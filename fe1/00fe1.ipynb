{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\agath\\anaconda3\\envs\\strive_school\\lib\\site-packages (0.24.2)Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\agath\\anaconda3\\envs\\strive_school\\lib\\site-packages (from scikit-learn) (1.19.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\agath\\anaconda3\\envs\\strive_school\\lib\\site-packages (from scikit-learn) (2.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\agath\\anaconda3\\envs\\strive_school\\lib\\site-packages (from scikit-learn) (1.6.2)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\agath\\anaconda3\\envs\\strive_school\\lib\\site-packages (from scikit-learn) (1.0.1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mjnuJ19dJV7v"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas   1.2.3\n",
      "Sklearn  0.24.2\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from IPython.display import clear_output\n",
    "import numpy    as np\n",
    "import pandas   as pd\n",
    "import seaborn  as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn  as skl\n",
    "\n",
    "from sklearn import pipeline      # Pipeline\n",
    "from sklearn import preprocessing # OrdinalEncoder, LabelEncoder\n",
    "from sklearn import impute\n",
    "from sklearn import compose\n",
    "from sklearn import model_selection # train_test_split\n",
    "from sklearn import metrics         # accuracy_score, balanced_accuracy_score, plot_confusion_matrix\n",
    "from sklearn import set_config\n",
    "\n",
    "set_config(display='diagram') # Useful for display the pipeline\n",
    "\n",
    "print(\"Pandas  \", pd.__version__)\n",
    "print(\"Sklearn \", skl.__version__) # Try to use 0.24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the dataset\n",
    "- **CLOUD = True**: Download dataset from Kaggle. Necesary for cloud enviroments like COLAB. **Specify your [kaggle credentials](https://www.kaggle.com/docs/api)**.\n",
    "- **CLOUD = False**: Get the dataset from your local machine. **Specify the data path**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in c:\\users\\agath\\anaconda3\\envs\\strive_school\\lib\\site-packages (1.5.12)\n",
      "Requirement already satisfied: tqdm in c:\\users\\agath\\anaconda3\\envs\\strive_school\\lib\\site-packages (from kaggle) (4.60.0)\n",
      "Requirement already satisfied: requests in c:\\users\\agath\\anaconda3\\envs\\strive_school\\lib\\site-packages (from kaggle) (2.25.1)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\agath\\appdata\\roaming\\python\\python38\\site-packages (from kaggle) (1.14.0)\n",
      "Requirement already satisfied: python-slugify in c:\\users\\agath\\anaconda3\\envs\\strive_school\\lib\\site-packages (from kaggle) (5.0.0)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\agath\\anaconda3\\envs\\strive_school\\lib\\site-packages (from kaggle) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\agath\\anaconda3\\envs\\strive_school\\lib\\site-packages (from kaggle) (2.8.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\agath\\anaconda3\\envs\\strive_school\\lib\\site-packages (from kaggle) (2020.12.5)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in c:\\users\\agath\\anaconda3\\envs\\strive_school\\lib\\site-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\agath\\anaconda3\\envs\\strive_school\\lib\\site-packages (from requests->kaggle) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\agath\\anaconda3\\envs\\strive_school\\lib\\site-packages (from requests->kaggle) (2.10)\n",
      "titanic.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    }
   ],
   "source": [
    "CLOUD = False\n",
    "\n",
    "if CLOUD:\n",
    "    import os\n",
    "    os.environ['KAGGLE_USERNAME'] = \"agathiyaraja\"\n",
    "    os.environ['KAGGLE_KEY']      = \"1gfdfdhdafbdngnjrygvfszvbahc\"  # See https://www.kaggle.com/docs/api\n",
    "    !pip install --upgrade kaggle\n",
    "    !kaggle competitions download -c titanic\n",
    "    DATA_PATH = \"D:/Strive_school/AI_Strive/M4_Feature_Eng/titanic/\"\n",
    "\n",
    "else:\n",
    "    DATA_PATH = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wAy8TnVPJV8S"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train DataFrame: (891, 11)\n",
      "Test DataFrame:  (418, 10)\n"
     ]
    }
   ],
   "source": [
    "df      = pd.read_csv(DATA_PATH + \"train.csv\", index_col='PassengerId')\n",
    "df_test = pd.read_csv(DATA_PATH + \"test.csv\",  index_col='PassengerId')\n",
    "\n",
    "print(\"Train DataFrame:\", df.shape)\n",
    "print(\"Test DataFrame: \", df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check missings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived      0\n",
       "Pclass        0\n",
       "Name          0\n",
       "Sex           0\n",
       "Age         177\n",
       "SibSp         0\n",
       "Parch         0\n",
       "Ticket        0\n",
       "Fare          0\n",
       "Cabin       687\n",
       "Embarked      2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass        0\n",
       "Name          0\n",
       "Sex           0\n",
       "Age          86\n",
       "SibSp         0\n",
       "Parch         0\n",
       "Ticket        0\n",
       "Fare          1\n",
       "Cabin       327\n",
       "Embarked      0\n",
       "Title         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.isnull().sum()\n",
    "#python --version\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1 (2pts):\n",
    "Extract the title (Mr, Mrs, ... ) from the \"Name\" column.\n",
    "\n",
    "Tips:\n",
    "- split(',')[1] to get the 2nd part, and remove the surnamename\n",
    "- split('.')[0] to get the 1str part, and remove the name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cac1de4ed2d966fcdf707a8bfd131fba",
     "grade": false,
     "grade_id": "cell-d56107842f0f54d2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# CODE HERE get_Title_from_Name funtion\n",
    "# Create this function using lambda (not def)\n",
    "def get_Title_from_Name(string):\n",
    "    string_ret = string.split(\", \")[1].split(\".\")[0]\n",
    "    return string_ret\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n",
    "\n",
    "df['Title']      = df['Name'].map(get_Title_from_Name)\n",
    "df_test['Title'] = df_test['Name'].map(get_Title_from_Name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f23c4d567e5fb4f4b69a001df14c6f7c",
     "grade": true,
     "grade_id": "cell-f3d989a17018344b",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert df['Title'].values[0] == \"Mr\"\n",
    "assert df['Title'].values[1] == \"Mrs\"\n",
    "assert df['Title'].values[2] == \"Miss\"\n",
    "\n",
    "assert df_test['Title'].values[0] == \"Mr\"\n",
    "assert df_test['Title'].values[1] == \"Mrs\"\n",
    "assert df_test['Title'].values[414] == \"Dona\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2 (1pts):\n",
    "Apply the title_dictionary to get a better information about the title. You have to overwrite the Title variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_dictionary = {\n",
    "    \"Capt\": \"Officer\",\n",
    "    \"Col\": \"Officer\",\n",
    "    \"Major\": \"Officer\",\n",
    "    \"Jonkheer\": \"Royalty\",\n",
    "    \"Don\": \"Royalty\",\n",
    "    \"Sir\" : \"Royalty\",\n",
    "    \"Dr\": \"Officer\",\n",
    "    \"Rev\": \"Officer\",\n",
    "    \"the Countess\":\"Royalty\",\n",
    "    \"Mme\": \"Mrs\",\n",
    "    \"Mlle\": \"Miss\",\n",
    "    \"Ms\": \"Mrs\",\n",
    "    \"Mr\" : \"Mr\",\n",
    "    \"Mrs\" : \"Mrs\",\n",
    "    \"Miss\" : \"Miss\",\n",
    "    \"Master\" : \"Master\",\n",
    "    \"Lady\" : \"Royalty\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "da7233548e7218eded680b5edb7963de",
     "grade": false,
     "grade_id": "cell-5c6a842c812fafda",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId\n",
       "892         Mr\n",
       "893        Mrs\n",
       "894         Mr\n",
       "895         Mr\n",
       "896        Mrs\n",
       "         ...  \n",
       "1305        Mr\n",
       "1306      Dona\n",
       "1307        Mr\n",
       "1308        Mr\n",
       "1309    Master\n",
       "Name: Title, Length: 418, dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use map to apply the prevous dict\n",
    "\n",
    "df[\"Title\"] = df[\"Title\"].replace(title_dictionary) \n",
    "df_test[\"Title\"] = df_test[\"Title\"].replace(title_dictionary)\n",
    "df_test[\"Title\"]\n",
    "\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "96a09f1cde63b704ff2f391309c30690",
     "grade": true,
     "grade_id": "cell-669f5a637e57e835",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert df['Title'].values[886] == \"Officer\"\n",
    "assert df_test['Title'].values[417] == \"Master\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise OPTINAL (0pts):\n",
    "Try to extract some information from the feature **Ticket**. Search on Internet if that colum has some kind of information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId\n",
       "892                 330911\n",
       "893                 363272\n",
       "894                 240276\n",
       "895                 315154\n",
       "896                3101298\n",
       "               ...        \n",
       "1305             A.5. 3236\n",
       "1306              PC 17758\n",
       "1307    SOTON/O.Q. 3101262\n",
       "1308                359309\n",
       "1309                  2668\n",
       "Name: Ticket, Length: 418, dtype: object"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['Ticket']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise OPTIONAL (0pts):\n",
    "Try to extract some information from the feature **Cabin**. Search on Internet if that colum has some kind of information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId\n",
       "892      NaN\n",
       "893      NaN\n",
       "894      NaN\n",
       "895      NaN\n",
       "896      NaN\n",
       "        ... \n",
       "1305     NaN\n",
       "1306    C105\n",
       "1307     NaN\n",
       "1308     NaN\n",
       "1309     NaN\n",
       "Name: Cabin, Length: 418, dtype: object"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['Cabin']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "For X data, notice that...\n",
    "- We drop Survived because is the target variable\n",
    "- We drop Name because we have extracted the Title: Mr, Mrs, ...\n",
    "- We drop Ticket because it has no information -> see df.Ticket.nunique()\n",
    "- We drop Cabin because it has a lot of missings (77% are missings)\n",
    "\n",
    "Then, we identify **numerical** variables and **categorical** variables,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(columns=[\"Survived\", 'Name', 'Ticket', 'Cabin']) # X DATA (WILL BE TRAIN+VALID DATA)\n",
    "y = df[\"Survived\"] # 0 = No, 1 = Yes\n",
    "\n",
    "x_test = df_test.drop(columns=['Name', 'Ticket', 'Cabin']) # # X_TEST DATA (NEW DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Numerical features:\n",
      " ['Pclass', 'SibSp', 'Parch', 'Fare', 'Age']\n",
      "\n",
      "Categorical features:\n",
      " ['Sex', 'Embarked', 'Title']\n"
     ]
    }
   ],
   "source": [
    "cat_vars  = ['Sex', 'Embarked', 'Title']         # x.select_dtypes(include=[object]).columns.values.tolist()\n",
    "num_vars  = ['Pclass', 'SibSp', 'Parch', 'Fare', 'Age'] # x.select_dtypes(exclude=[object]).columns.values.tolist()\n",
    "\n",
    "print(\"\\nNumerical features:\\n\", num_vars)\n",
    "print(\"\\nCategorical features:\\n\", cat_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3 (2pts):\n",
    "Create a **ColumnTransformer for Tree Models**. You need to create 2 pipelines (one for numerical and other for categories). Remember:\n",
    "- Categorical pipeline: Some SimpleImputer -> Some Encoder\n",
    "- Numerical pipeline: Some SimpleImputer -> NO Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4a99fc5ecc693dc549b0e1560c568eea",
     "grade": false,
     "grade_id": "cell-c607e75fb38ea248",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "num_4_treeModels = pipeline.Pipeline(steps=[\n",
    "    ('imputer', impute.SimpleImputer(strategy='mean', add_indicator=False))]) # mean, median\n",
    "\n",
    "cat_4_treeModels = pipeline.Pipeline(steps=[\n",
    "    ('imputer', impute.SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('ordinal', preprocessing.OrdinalEncoder(handle_unknown='ignore'))])\n",
    "tree_prepro = compose.ColumnTransformer(transformers=[\n",
    "    ('num', num_4_treeModels, num_vars),\n",
    "    ('cat', cat_4_treeModels, cat_vars),],\n",
    "    remainder='drop')\n",
    "                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "00bde840843413a4f57c4480f8930ef0",
     "grade": true,
     "grade_id": "cell-e636558135fb5975",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(tree_prepro)      is compose._column_transformer.ColumnTransformer\n",
    "assert type(num_4_treeModels) is pipeline.Pipeline\n",
    "assert type(cat_4_treeModels) is pipeline.Pipeline\n",
    "assert len(num_4_treeModels) == 1\n",
    "assert len(cat_4_treeModels) == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4 (1pts):\n",
    "1. Complete the diccionary with some Tree Models.\n",
    "2. Then we put each model in a Pipeline where:\n",
    "   - first is the prepocessing with the column Transformer\n",
    "   - Then is the Tree model\n",
    "3. Display the fullpipeline of the LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree          import DecisionTreeClassifier\n",
    "from sklearn.ensemble      import RandomForestClassifier\n",
    "from sklearn.ensemble      import ExtraTreesClassifier\n",
    "from sklearn.ensemble      import AdaBoostClassifier\n",
    "from sklearn.ensemble      import GradientBoostingClassifier\n",
    "from sklearn.experimental  import enable_hist_gradient_boosting # Necesary for HistGradientBoostingClassifier\n",
    "from sklearn.ensemble      import HistGradientBoostingClassifier\n",
    "from xgboost               import XGBClassifier\n",
    "from lightgbm              import LGBMClassifier\n",
    "from catboost              import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f23af11f3af791efa5687477c0a4c9d6",
     "grade": false,
     "grade_id": "cell-76a3be8223730c5a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "tree_classifiers = {\n",
    "  \"Decision Tree\": DecisionTreeClassifier(),\n",
    "  \"Extra Trees\":\n",
    "  \"Random Forest\":\n",
    "  \"AdaBoost\":\n",
    "  \"Skl GBM\":\n",
    "  \"Skl HistGBM\":\n",
    "  \"XGBoost\":\n",
    "  \"LightGBM\":\n",
    "  \"CatBoost\":\n",
    "tree_classifiers = {name: pipeline.make_pipeline(tree_prepro, model) for name, model in tree_classifiers.items()}\n",
    "tree_classifiers[\"LightGBM\"]\n",
    "\"\"\";\n",
    "\n",
    "\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n",
    "\n",
    "tree_classifiers = {name: pipeline.make_pipeline(tree_prepro, model) for name, model in tree_classifiers.items()}\n",
    "\n",
    "tree_classifiers[\"LightGBM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2355552b3ce823e44fdaea06394e054c",
     "grade": true,
     "grade_id": "cell-d4744022b37e2e9b",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "for pipe in tree_classifiers.values():\n",
    "    assert type(pipe) is pipeline.Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 5 (3pts):\n",
    "Define a simple split validation strategy with:\n",
    "- 80% for train\n",
    "- 20% for validation\n",
    "- With stratification\n",
    "- random_state=0\n",
    "\n",
    "And train all the models in a for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "deletable": false,
    "id": "kY1uWk6-OcLw",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e48597a78f468a95abf116052e9f68e6",
     "grade": false,
     "grade_id": "cell-64f17e0d448bca7e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "3562463f-3197-424c-dc82-b07ad579e9cc"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "x_train, x_val, y_train, y_val = model_selection.train_test_split(\n",
    "    # CODE HERE\n",
    ")\n",
    "\"\"\"\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n",
    "\n",
    "\n",
    "results = pd.DataFrame({'Model': [], 'Accuracy': [], 'Bal Acc.': [], 'Time': []})\n",
    "\n",
    "\"\"\"\n",
    "for model_name, model in tree_classifiers.items():\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # FOR EVERY PIPELINE (PREPRO + MODEL) -> TRAIN WITH TRAIN DATA (x_train)\n",
    "    \n",
    "    # GET PREDICTIONS USING x_val\n",
    "    pred = # CODE HERE\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "\n",
    "    results = results.append({\"Model\":    model_name,\n",
    "                              \"Accuracy\": metrics.accuracy_score(y_val, pred)*100,\n",
    "                              \"Bal Acc.\": metrics.balanced_accuracy_score(y_val, pred)*100,\n",
    "                              \"Time\":     total_time},\n",
    "                              ignore_index=True)\n",
    "                              \n",
    "                              \n",
    "\"\"\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "\n",
    "results_ord = results.sort_values(by=['Accuracy'], ascending=False, ignore_index=True)\n",
    "results_ord.index += 1 \n",
    "results_ord.style.bar(subset=['Accuracy', 'Bal Acc.'], vmin=0, vmax=100, color='#5fba7d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dde6f91a6185745a813882e0c1f997bc",
     "grade": true,
     "grade_id": "cell-af27b33fe88ad384",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert results_ord[\"Accuracy\"].min() > 75\n",
    "assert results_ord[\"Bal Acc.\"].min() > 75\n",
    "assert len(results_ord) == 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6 (3pts):\n",
    "Define a 10 Fold cross validation strategy with:\n",
    "- With stratification\n",
    "- shuffle=True\n",
    "- random_state=0\n",
    "\n",
    "And train all the models in a for loop.\n",
    "\n",
    "Tip you can use **[cross_val_predict](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_predict.html)** for both training and predict with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b9238f7916249fc81179a78b5492e5d4",
     "grade": false,
     "grade_id": "cell-37bf16dc25b43732",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "skf = model_selection.StratifiedKFold(\n",
    "    # CODE HERE\n",
    ")\n",
    "\"\"\"\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "\n",
    "results = pd.DataFrame({'Model': [], 'Accuracy': [], 'Bal Acc.': [], 'Time': []})\n",
    "\n",
    "\"\"\"\n",
    "for model_name, model in tree_classifiers.items():\n",
    "    start_time = time.time()\n",
    "        \n",
    "    # TRAIN AND GET PREDICTIONS USING cross_val_predict() and x,y\n",
    "    pred = # CODE HERE\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "\n",
    "    results = results.append({\"Model\":    model_name,\n",
    "                              \"Accuracy\": metrics.accuracy_score(y_val, pred)*100,\n",
    "                              \"Bal Acc.\": metrics.balanced_accuracy_score(y_val, pred)*100,\n",
    "                              \"Time\":     total_time},\n",
    "                              ignore_index=True)\n",
    "                              \n",
    "                              \n",
    "\"\"\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "\n",
    "results_ord = results.sort_values(by=['Accuracy'], ascending=False, ignore_index=True)\n",
    "results_ord.index += 1 \n",
    "results_ord.style.bar(subset=['Accuracy', 'Bal Acc.'], vmin=0, vmax=100, color='#5fba7d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "355f8e8321aae7be679a8d16b25172f2",
     "grade": true,
     "grade_id": "cell-57cc085faad513cf",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert results_ord[\"Accuracy\"].min() > 75\n",
    "assert results_ord[\"Bal Acc.\"].min() > 75\n",
    "assert len(results_ord) == 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 7.1\n",
    "Train with all data the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "monuuQhHL7B_",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "088ae511ec2eb947de2bff002e75d460",
     "grade": false,
     "grade_id": "cell-031a656e1e811717",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# best_model = tree_classifiers[\"SELECT MY BEST MODEL HERE\"]\n",
    "\n",
    "# Fit best model with all data\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 7.2 (2pts)\n",
    "With your best model, generate the predicitions for test data (x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "031ab122b02b5833236370a53d148daf",
     "grade": false,
     "grade_id": "cell-44b93a0dbd4eb6fc",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test_pred = # Get the predictions for x_test\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "180b37cf4a0276bdf509220b1706a8aa",
     "grade": true,
     "grade_id": "cell-a29fc8d24284520e",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(test_pred) == 418\n",
    "assert np.unique(test_pred).tolist() == [0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 7.3\n",
    "\n",
    "Submit to kaggle.\n",
    "\n",
    "- You can use the kaggle command line app. Check https://github.com/Kaggle/kaggle-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame(test_pred, index=x_test.index, columns=[\"Survived\"])\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(\"sub.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions submit -c titanic -f sub.csv -m \"My submission message\""
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "Titanic LogReg.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "name": "seminar13_optional_practice_trees_titanic.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
