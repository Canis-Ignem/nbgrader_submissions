{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --upgrade scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-09T21:09:49.098178Z",
     "start_time": "2021-05-09T21:09:13.952595Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "mjnuJ19dJV7v"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas   1.2.4\n",
      "Sklearn  0.24.1\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from IPython.display import clear_output\n",
    "import numpy    as np\n",
    "import pandas   as pd\n",
    "import seaborn  as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn  as skl\n",
    "\n",
    "from sklearn import pipeline      # Pipeline\n",
    "from sklearn import preprocessing # OrdinalEncoder, LabelEncoder\n",
    "from sklearn import impute\n",
    "from sklearn import compose\n",
    "from sklearn import model_selection # train_test_split\n",
    "from sklearn import metrics         # accuracy_score, balanced_accuracy_score, plot_confusion_matrix\n",
    "from sklearn import set_config\n",
    "\n",
    "set_config(display='diagram') # Useful for display the pipeline\n",
    "\n",
    "print(\"Pandas  \", pd.__version__)\n",
    "print(\"Sklearn \", skl.__version__) # Try to use 0.24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the dataset\n",
    "- **CLOUD = True**: Download dataset from Kaggle. Necesary for cloud enviroments like COLAB. **Specify your [kaggle credentials](https://www.kaggle.com/docs/api)**.\n",
    "- **CLOUD = False**: Get the dataset from your local machine. **Specify the data path**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-09T21:09:49.113138Z",
     "start_time": "2021-05-09T21:09:49.100174Z"
    }
   },
   "outputs": [],
   "source": [
    "CLOUD = False\n",
    "\n",
    "if CLOUD:\n",
    "    import os\n",
    "    os.environ['KAGGLE_USERNAME'] = \"your_kaggle_username\"\n",
    "    os.environ['KAGGLE_KEY']      = \"your_kaggle_api_key\"  # See https://www.kaggle.com/docs/api\n",
    "    !pip install --upgrade kaggle\n",
    "    !kaggle competitions download -c titanic\n",
    "    DATA_PATH = \"./\"\n",
    "\n",
    "else:\n",
    "    DATA_PATH = \"../../Datasets/Tabular/titanic/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-09T21:09:49.583573Z",
     "start_time": "2021-05-09T21:09:49.116130Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "wAy8TnVPJV8S"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train DataFrame: (891, 11)\n",
      "Test DataFrame:  (418, 10)\n"
     ]
    }
   ],
   "source": [
    "df      = pd.read_csv(DATA_PATH + \"train.csv\", index_col='PassengerId')\n",
    "df_test = pd.read_csv(DATA_PATH + \"test.csv\",  index_col='PassengerId')\n",
    "\n",
    "print(\"Train DataFrame:\", df.shape)\n",
    "print(\"Test DataFrame: \", df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check missings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-09T21:09:49.692643Z",
     "start_time": "2021-05-09T21:09:49.585569Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived      0\n",
       "Pclass        0\n",
       "Name          0\n",
       "Sex           0\n",
       "Age         177\n",
       "SibSp         0\n",
       "Parch         0\n",
       "Ticket        0\n",
       "Fare          0\n",
       "Cabin       687\n",
       "Embarked      2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-09T21:09:49.755448Z",
     "start_time": "2021-05-09T21:09:49.695636Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass        0\n",
       "Name          0\n",
       "Sex           0\n",
       "Age          86\n",
       "SibSp         0\n",
       "Parch         0\n",
       "Ticket        0\n",
       "Fare          1\n",
       "Cabin       327\n",
       "Embarked      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1 (2pts):\n",
    "Extract the title (Mr, Mrs, ... ) from the \"Name\" column.\n",
    "\n",
    "Tips:\n",
    "- split(',')[1] to get the 2nd part, and remove the surnamename\n",
    "- split('.')[0] to get the 1str part, and remove the name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-09T21:09:50.127854Z",
     "start_time": "2021-05-09T21:09:49.763429Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cac1de4ed2d966fcdf707a8bfd131fba",
     "grade": false,
     "grade_id": "cell-d56107842f0f54d2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>Mrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Miss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>Mrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass  \\\n",
       "PassengerId                     \n",
       "1                   0       3   \n",
       "2                   1       1   \n",
       "3                   1       3   \n",
       "4                   1       1   \n",
       "5                   0       3   \n",
       "\n",
       "                                                          Name     Sex   Age  \\\n",
       "PassengerId                                                                    \n",
       "1                                      Braund, Mr. Owen Harris    male  22.0   \n",
       "2            Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n",
       "3                                       Heikkinen, Miss. Laina  female  26.0   \n",
       "4                 Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n",
       "5                                     Allen, Mr. William Henry    male  35.0   \n",
       "\n",
       "             SibSp  Parch            Ticket     Fare Cabin Embarked Title  \n",
       "PassengerId                                                                \n",
       "1                1      0         A/5 21171   7.2500   NaN        S    Mr  \n",
       "2                1      0          PC 17599  71.2833   C85        C   Mrs  \n",
       "3                0      0  STON/O2. 3101282   7.9250   NaN        S  Miss  \n",
       "4                1      0            113803  53.1000  C123        S   Mrs  \n",
       "5                0      0            373450   8.0500   NaN        S    Mr  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CODE HERE get_Title_from_Name funtion\n",
    "# Create this function using lambda (not def)\n",
    "\n",
    "get_Title_from_Name = lambda x : x.split(',')[1].split('.')[0].strip()\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# df2 = df.assign(Title = lambda name: ((df['Name']).split(',').split('.')))\n",
    "# df = df.assign(Title = lambda x: (x['Name'].str.split('.')))\n",
    "# df = df.assign(Title = lambda x: (x['Name'].str.split('.')))\n",
    "# df[\"Title\"] = df['Name'].apply(lambda x : x.split(',')[1].split('.')[0].strip())\n",
    "# df = df.assign(Title = lambda x: (x['Name'].str.split(',').str.split('.')))\n",
    "\n",
    "# title_np = np.array(df['Name'].str.split(','))\n",
    "# for i in title_np:\n",
    "#     del i[0]\n",
    "# print(title_np)\n",
    "# my_np =np.array(df[\"Title\"])\n",
    "# my_list = list(my_np)\n",
    "# my_list = my_list.split('.')\n",
    "# my_list2 = []\n",
    "\n",
    "\n",
    "# print(df)\n",
    "\n",
    "\n",
    "# raise NotImplementedError()\n",
    "\n",
    "df['Title']      = df['Name'].map(get_Title_from_Name)\n",
    "df_test['Title'] = df_test['Name'].map(get_Title_from_Name)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-09T21:09:50.176753Z",
     "start_time": "2021-05-09T21:09:50.129850Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f23c4d567e5fb4f4b69a001df14c6f7c",
     "grade": true,
     "grade_id": "cell-f3d989a17018344b",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert df['Title'].values[0] == \"Mr\"\n",
    "assert df['Title'].values[1] == \"Mrs\"\n",
    "assert df['Title'].values[2] == \"Miss\"\n",
    "\n",
    "assert df_test['Title'].values[0] == \"Mr\"\n",
    "assert df_test['Title'].values[1] == \"Mrs\"\n",
    "assert df_test['Title'].values[414] == \"Dona\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2 (1pts):\n",
    "Apply the title_dictionary to get a better information about the title. You have to overwrite the Title variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-09T21:09:50.439582Z",
     "start_time": "2021-05-09T21:09:50.181739Z"
    }
   },
   "outputs": [],
   "source": [
    "title_dictionary = {\n",
    "    \"Capt\": \"Officer\",\n",
    "    \"Col\": \"Officer\",\n",
    "    \"Major\": \"Officer\",\n",
    "    \"Jonkheer\": \"Royalty\",\n",
    "    \"Don\": \"Royalty\",\n",
    "    \"Sir\" : \"Royalty\",\n",
    "    \"Dr\": \"Officer\",\n",
    "    \"Rev\": \"Officer\",\n",
    "    \"the Countess\":\"Royalty\",\n",
    "    \"Mme\": \"Mrs\",\n",
    "    \"Mlle\": \"Miss\",\n",
    "    \"Ms\": \"Mrs\",\n",
    "    \"Mr\" : \"Mr\",\n",
    "    \"Mrs\" : \"Mrs\",\n",
    "    \"Miss\" : \"Miss\",\n",
    "    \"Master\" : \"Master\",\n",
    "    \"Lady\" : \"Royalty\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-09T21:09:50.595363Z",
     "start_time": "2021-05-09T21:09:50.447561Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "da7233548e7218eded680b5edb7963de",
     "grade": false,
     "grade_id": "cell-5c6a842c812fafda",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891\n",
      "418\n"
     ]
    }
   ],
   "source": [
    "# Use map to apply the prevous dict\n",
    "\n",
    "df[\"Title\"] =  df['Title'].map(title_dictionary)\n",
    "df_test[\"Title\"] = df_test['Title'].map(title_dictionary)\n",
    "print(len(df[\"Title\"]))\n",
    "print(len(df_test[\"Title\"]))\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-09T21:09:50.751740Z",
     "start_time": "2021-05-09T21:09:50.597357Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "96a09f1cde63b704ff2f391309c30690",
     "grade": true,
     "grade_id": "cell-669f5a637e57e835",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert df['Title'].values[886] == \"Officer\"\n",
    "assert df_test['Title'].values[417] == \"Master\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise OPTINAL (0pts):\n",
    "Try to extract some information from the feature **Ticket**. Search on Internet if that colum has some kind of information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-09T21:09:50.925707Z",
     "start_time": "2021-05-09T21:09:50.753732Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Survived  Pclass  \\\n",
      "PassengerId                     \n",
      "1                   0       3   \n",
      "2                   1       1   \n",
      "3                   1       3   \n",
      "4                   1       1   \n",
      "5                   0       3   \n",
      "\n",
      "                                                          Name     Sex   Age  \\\n",
      "PassengerId                                                                    \n",
      "1                                      Braund, Mr. Owen Harris    male  22.0   \n",
      "2            Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n",
      "3                                       Heikkinen, Miss. Laina  female  26.0   \n",
      "4                 Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n",
      "5                                     Allen, Mr. William Henry    male  35.0   \n",
      "\n",
      "             SibSp  Parch            Ticket     Fare Cabin Embarked Title  \n",
      "PassengerId                                                                \n",
      "1                1      0         A/5 21171   7.2500   NaN        S    Mr  \n",
      "2                1      0          PC 17599  71.2833   C85        C   Mrs  \n",
      "3                0      0  STON/O2. 3101282   7.9250   NaN        S  Miss  \n",
      "4                1      0            113803  53.1000  C123        S   Mrs  \n",
      "5                0      0            373450   8.0500   NaN        S    Mr  \n"
     ]
    }
   ],
   "source": [
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise OPTIONAL (0pts):\n",
    "Try to extract some information from the feature **Cabin**. Search on Internet if that colum has some kind of information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-09T21:09:51.141609Z",
     "start_time": "2021-05-09T21:09:50.929694Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId\n",
       "892      NaN\n",
       "893      NaN\n",
       "894      NaN\n",
       "895      NaN\n",
       "896      NaN\n",
       "        ... \n",
       "1305     NaN\n",
       "1306    C105\n",
       "1307     NaN\n",
       "1308     NaN\n",
       "1309     NaN\n",
       "Name: Cabin, Length: 418, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['Cabin']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "For X data, notice that...\n",
    "- We drop Survived because is the target variable\n",
    "- We drop Name because we have extracted the Title: Mr, Mrs, ...\n",
    "- We drop Ticket because it has no information -> see df.Ticket.nunique()\n",
    "- We drop Cabin because it has a lot of missings (77% are missings)\n",
    "\n",
    "Then, we identify **numerical** variables and **categorical** variables,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-09T21:09:51.360668Z",
     "start_time": "2021-05-09T21:09:51.145599Z"
    }
   },
   "outputs": [],
   "source": [
    "x = df.drop(columns=[\"Survived\", 'Name', 'Ticket', 'Cabin']) # X DATA (WILL BE TRAIN+VALID DATA)\n",
    "y = df[\"Survived\"] # 0 = No, 1 = Yes\n",
    "\n",
    "x_test = df_test.drop(columns=['Name', 'Ticket', 'Cabin']) # # X_TEST DATA (NEW DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-09T21:09:52.538758Z",
     "start_time": "2021-05-09T21:09:52.527786Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Numerical features:\n",
      " ['Pclass', 'SibSp', 'Parch', 'Fare', 'Age']\n",
      "\n",
      "Categorical features:\n",
      " ['Sex', 'Embarked', 'Title']\n"
     ]
    }
   ],
   "source": [
    "cat_vars  = ['Sex', 'Embarked', 'Title']         # x.select_dtypes(include=[object]).columns.values.tolist()\n",
    "num_vars  = ['Pclass', 'SibSp', 'Parch', 'Fare', 'Age'] # x.select_dtypes(exclude=[object]).columns.values.tolist()\n",
    "\n",
    "print(\"\\nNumerical features:\\n\", num_vars)\n",
    "print(\"\\nCategorical features:\\n\", cat_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3 (2pts):\n",
    "Create a **ColumnTransformer for Tree Models**. You need to create 2 pipelines (one for numerical and other for categories). Remember:\n",
    "- Categorical pipeline: Some SimpleImputer -> Some Encoder\n",
    "- Numerical pipeline: Some SimpleImputer -> NO Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-09T21:10:03.562815Z",
     "start_time": "2021-05-09T21:10:03.544894Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4a99fc5ecc693dc549b0e1560c568eea",
     "grade": false,
     "grade_id": "cell-c607e75fb38ea248",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.compose._column_transformer.ColumnTransformer'>\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "<class 'sklearn.pipeline.Pipeline'>\n",
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "num_preprocessing = pipeline.Pipeline(steps=[\n",
    "  # Some SimpleImputer here\n",
    "])\n",
    "\n",
    "cat_preporcessing = pipeline.Pipeline(steps=[\n",
    "  # Some SimpleImputer here\n",
    "  # Some Encoder here. Remember to handle_unknown\n",
    "])\n",
    "\n",
    "tree_prepro = compose.ColumnTransformer(transformers=[\n",
    "    ('num', num_preprocessing, num_vars),\n",
    "    ('cat', cat_preporcessing, cat_vars),\n",
    "], remainder='drop') # Drop other vars not specified in num_vars or cat_vars\n",
    "\n",
    "tree_prepro\n",
    "\"\"\";\n",
    "\n",
    "# YOUR CODE HERE\n",
    "num_4_treeModels = pipeline.Pipeline(steps=[('imputer', impute.SimpleImputer(strategy= 'mean', add_indicator=False)),\n",
    "                                             ('scaler', preprocessing.StandardScaler())])\n",
    "cat_4_treeModels = pipeline.Pipeline(steps= [('imputer', impute.SimpleImputer(strategy= 'constant', fill_value='missing')),\n",
    "                                             ('onehot', preprocessing.OneHotEncoder(handle_unknown='ignore'))])\n",
    "tree_prepro = compose.ColumnTransformer(transformers=[('num', num_4_treeModels, num_vars),\n",
    "                                                ('cat', cat_4_treeModels, cat_vars)], remainder='drop')\n",
    "\n",
    "\n",
    "print(type(tree_prepro))\n",
    "print(type(num_4_treeModels))\n",
    "print(type(cat_4_treeModels))\n",
    "print(len(num_4_treeModels))\n",
    "print(len(cat_4_treeModels))\n",
    "# raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-09T21:10:07.980400Z",
     "start_time": "2021-05-09T21:10:06.865420Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "00bde840843413a4f57c4480f8930ef0",
     "grade": true,
     "grade_id": "cell-e636558135fb5975",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-864c4e73e803>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_4_treeModels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPipeline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcat_4_treeModels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPipeline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_4_treeModels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcat_4_treeModels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert type(tree_prepro)      is compose._column_transformer.ColumnTransformer\n",
    "assert type(num_4_treeModels) is pipeline.Pipeline\n",
    "assert type(cat_4_treeModels) is pipeline.Pipeline\n",
    "assert len(num_4_treeModels) == 1\n",
    "assert len(cat_4_treeModels) == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4 (1pts):\n",
    "1. Complete the diccionary with some Tree Models.\n",
    "2. Then we put each model in a Pipeline where:\n",
    "   - first is the prepocessing with the column Transformer\n",
    "   - Then is the Tree model\n",
    "3. Display the fullpipeline of the LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-09T21:10:17.429098Z",
     "start_time": "2021-05-09T21:10:14.221884Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lightgbm'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-4942c4a5fb37>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m      \u001b[1;32mimport\u001b[0m \u001b[0mHistGradientBoostingClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m               \u001b[1;32mimport\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mlightgbm\u001b[0m              \u001b[1;32mimport\u001b[0m \u001b[0mLGBMClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcatboost\u001b[0m              \u001b[1;32mimport\u001b[0m \u001b[0mCatBoostClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'lightgbm'"
     ]
    }
   ],
   "source": [
    "from sklearn.tree          import DecisionTreeClassifier\n",
    "from sklearn.ensemble      import RandomForestClassifier\n",
    "from sklearn.ensemble      import ExtraTreesClassifier\n",
    "from sklearn.ensemble      import AdaBoostClassifier\n",
    "from sklearn.ensemble      import GradientBoostingClassifier\n",
    "from sklearn.experimental  import enable_hist_gradient_boosting # Necesary for HistGradientBoostingClassifier\n",
    "from sklearn.ensemble      import HistGradientBoostingClassifier\n",
    "from xgboost               import XGBClassifier\n",
    "from lightgbm              import LGBMClassifier\n",
    "from catboost              import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f23af11f3af791efa5687477c0a4c9d6",
     "grade": false,
     "grade_id": "cell-76a3be8223730c5a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "tree_classifiers = {\n",
    "  \"Decision Tree\": DecisionTreeClassifier(),\n",
    "  \"Extra Trees\":\n",
    "  \"Random Forest\":\n",
    "  \"AdaBoost\":\n",
    "  \"Skl GBM\":\n",
    "  \"Skl HistGBM\":\n",
    "  \"XGBoost\":\n",
    "  \"LightGBM\":\n",
    "  \"CatBoost\":\n",
    "tree_classifiers = {name: pipeline.make_pipeline(tree_prepro, model) for name, model in tree_classifiers.items()}\n",
    "tree_classifiers[\"LightGBM\"]\n",
    "\"\"\";\n",
    "\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "tree_classifiers = {name: pipeline.make_pipeline(tree_prepro, model) for name, model in tree_classifiers.items()}\n",
    "\n",
    "tree_classifiers[\"LightGBM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2355552b3ce823e44fdaea06394e054c",
     "grade": true,
     "grade_id": "cell-d4744022b37e2e9b",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "for pipe in tree_classifiers.values():\n",
    "    assert type(pipe) is pipeline.Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 5 (3pts):\n",
    "Define a simple split validation strategy with:\n",
    "- 80% for train\n",
    "- 20% for validation\n",
    "- With stratification\n",
    "- random_state=0\n",
    "\n",
    "And train all the models in a for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "deletable": false,
    "id": "kY1uWk6-OcLw",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e48597a78f468a95abf116052e9f68e6",
     "grade": false,
     "grade_id": "cell-64f17e0d448bca7e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "3562463f-3197-424c-dc82-b07ad579e9cc"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "x_train, x_val, y_train, y_val = model_selection.train_test_split(\n",
    "    # CODE HERE\n",
    ")\n",
    "\"\"\"\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "\n",
    "results = pd.DataFrame({'Model': [], 'Accuracy': [], 'Bal Acc.': [], 'Time': []})\n",
    "\n",
    "\"\"\"\n",
    "for model_name, model in tree_classifiers.items():\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # FOR EVERY PIPELINE (PREPRO + MODEL) -> TRAIN WITH TRAIN DATA (x_train)\n",
    "    \n",
    "    # GET PREDICTIONS USING x_val\n",
    "    pred = # CODE HERE\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "\n",
    "    results = results.append({\"Model\":    model_name,\n",
    "                              \"Accuracy\": metrics.accuracy_score(y_val, pred)*100,\n",
    "                              \"Bal Acc.\": metrics.balanced_accuracy_score(y_val, pred)*100,\n",
    "                              \"Time\":     total_time},\n",
    "                              ignore_index=True)\n",
    "                              \n",
    "                              \n",
    "\"\"\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "\n",
    "results_ord = results.sort_values(by=['Accuracy'], ascending=False, ignore_index=True)\n",
    "results_ord.index += 1 \n",
    "results_ord.style.bar(subset=['Accuracy', 'Bal Acc.'], vmin=0, vmax=100, color='#5fba7d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dde6f91a6185745a813882e0c1f997bc",
     "grade": true,
     "grade_id": "cell-af27b33fe88ad384",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert results_ord[\"Accuracy\"].min() > 75\n",
    "assert results_ord[\"Bal Acc.\"].min() > 75\n",
    "assert len(results_ord) == 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6 (3pts):\n",
    "Define a 10 Fold cross validation strategy with:\n",
    "- With stratification\n",
    "- shuffle=True\n",
    "- random_state=0\n",
    "\n",
    "And train all the models in a for loop.\n",
    "\n",
    "Tip you can use **[cross_val_predict](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_predict.html)** for both training and predict with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b9238f7916249fc81179a78b5492e5d4",
     "grade": false,
     "grade_id": "cell-37bf16dc25b43732",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "skf = model_selection.StratifiedKFold(\n",
    "    # CODE HERE\n",
    ")\n",
    "\"\"\"\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "\n",
    "results = pd.DataFrame({'Model': [], 'Accuracy': [], 'Bal Acc.': [], 'Time': []})\n",
    "\n",
    "\"\"\"\n",
    "for model_name, model in tree_classifiers.items():\n",
    "    start_time = time.time()\n",
    "        \n",
    "    # TRAIN AND GET PREDICTIONS USING cross_val_predict() and x,y\n",
    "    pred = # CODE HERE\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "\n",
    "    results = results.append({\"Model\":    model_name,\n",
    "                              \"Accuracy\": metrics.accuracy_score(y_val, pred)*100,\n",
    "                              \"Bal Acc.\": metrics.balanced_accuracy_score(y_val, pred)*100,\n",
    "                              \"Time\":     total_time},\n",
    "                              ignore_index=True)\n",
    "                              \n",
    "                              \n",
    "\"\"\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "\n",
    "results_ord = results.sort_values(by=['Accuracy'], ascending=False, ignore_index=True)\n",
    "results_ord.index += 1 \n",
    "results_ord.style.bar(subset=['Accuracy', 'Bal Acc.'], vmin=0, vmax=100, color='#5fba7d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "355f8e8321aae7be679a8d16b25172f2",
     "grade": true,
     "grade_id": "cell-57cc085faad513cf",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert results_ord[\"Accuracy\"].min() > 75\n",
    "assert results_ord[\"Bal Acc.\"].min() > 75\n",
    "assert len(results_ord) == 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 7.1\n",
    "Train with all data the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "monuuQhHL7B_",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "088ae511ec2eb947de2bff002e75d460",
     "grade": false,
     "grade_id": "cell-031a656e1e811717",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# best_model = tree_classifiers[\"SELECT MY BEST MODEL HERE\"]\n",
    "\n",
    "# Fit best model with all data\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 7.2 (2pts)\n",
    "With your best model, generate the predicitions for test data (x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "031ab122b02b5833236370a53d148daf",
     "grade": false,
     "grade_id": "cell-44b93a0dbd4eb6fc",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test_pred = # Get the predictions for x_test\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "180b37cf4a0276bdf509220b1706a8aa",
     "grade": true,
     "grade_id": "cell-a29fc8d24284520e",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(test_pred) == 418\n",
    "assert np.unique(test_pred).tolist() == [0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 7.3\n",
    "\n",
    "Submit to kaggle.\n",
    "\n",
    "- You can use the kaggle command line app. Check https://github.com/Kaggle/kaggle-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame(test_pred, index=x_test.index, columns=[\"Survived\"])\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(\"sub.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions submit -c titanic -f sub.csv -m \"My submission message\""
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "Titanic LogReg.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "name": "seminar13_optional_practice_trees_titanic.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
